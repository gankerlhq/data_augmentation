{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "896bdf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import tsaug\n",
    "from tsaug import TimeWarp, Crop, Quantize, Drift, Reverse\n",
    "from tsaug.visualization import plot\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import plotly.graph_objects as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c1a77c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start date needs for final augmented data.\n",
    "HISTORICAL_DATE = '2022-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "807cce52",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE_FIELDS_CONFIG = {\n",
    "    \"metrics\": \"avgValue\",\n",
    "    \"cost\": \"costInUsd\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9bf200d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTILS FUNCTIONS\n",
    "date_format = '%Y-%m-%d'\n",
    "def calculate_number_of_augment_need(start_date, end_date, days_range):\n",
    "    res = math.ceil(((end_date - start_date)/days_range))\n",
    "    return res\n",
    "\n",
    "def date_parser(x):\n",
    "\treturn datetime.strptime(x, date_format)\n",
    "\n",
    "def add_noise(Y, X, scale=0.1):\n",
    "    Y_aug_noise, X_aug_noise = tsaug.AddNoise(scale=scale).augment(Y, X)\n",
    "    return Y_aug_noise, X_aug_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b2e60648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read real metrics data from VNG EP account\n",
    "cost_with_instances_info_file = './data/gcp_cost_with_instance_info.csv'\n",
    "cpu_utilize_file = './data/raw_gcp_cpu_utilization.json'\n",
    "network_in_file = './data/raw_gcp_network_in.json'\n",
    "network_out_file = './data/raw_gcp_network_out.json'\n",
    "df_cost_instances_info = pd.read_csv(cost_with_instances_info_file, sep=',', header=0, parse_dates=[2],\n",
    "        date_parser=date_parser,  dtype={'instanceId': str})\n",
    "df_cpu = pd.read_json(cpu_utilize_file, dtype={'instanceId': str})\n",
    "df_network_in = pd.read_json(network_in_file, dtype={'instanceId': str})\n",
    "df_network_out = pd.read_json(network_out_file, dtype={'instanceId': str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0860d992",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@param df_raw: data raw read from file\n",
    "@param instanceId: instance ID/ asset ID\n",
    "@param historical_date: starting date needs for data\n",
    "@param metric_type: new columne name for new dataset, example: CPUUtilization\n",
    "@return: df augmented to historical_date\n",
    "\"\"\"\n",
    "def augment_metrics(df_raw, asset_id, historical_date, metric_type, value_field):\n",
    "    asset_id_field = \"instanceId\"\n",
    "    datetime_field = \"datetime\"\n",
    "    \n",
    "    # Get data belonging to an asset\n",
    "    df_raw_i = df_raw[df_raw[asset_id_field] == asset_id].copy()\n",
    "    \n",
    "    # days_range: number of days in real data\n",
    "    start_date = df_raw_i.min(axis=0)[datetime_field].date()\n",
    "    end_date = df_raw_i.max(axis=0)[datetime_field].date()\n",
    "    days_range = end_date - start_date + timedelta(days=1)\n",
    "    \n",
    "    # Build X-axis, values from 0 to length of X. X with date values is causing errors when augmenting.\n",
    "    X = np.arange(len(df_raw_i))\n",
    "    \n",
    "    # Build X-axis with date values, use for final dataset, not to augment.\n",
    "    X_date = df_raw_i[datetime_field].map(lambda x: int(x.timestamp()*1000)).tolist()\n",
    "    \n",
    "    # Build Y axis\n",
    "    Y = df_raw_i[value_field].tolist()\n",
    "    Y = np.array(Y)\n",
    "    \n",
    "    # Augment Y and X. Results are augmented Y; X remains the same.\n",
    "    Y_aug_noise, X_aug_noise = add_noise(Y, X)\n",
    "    \n",
    "    # Calculate number of loops until date reach historical date\n",
    "    loops_count = calculate_number_of_augment_need(historical_date.date(), start_date,days_range)\n",
    "    \n",
    "    # Map dates to timestamp format\n",
    "    X_date = df_raw_i[datetime_field].map(lambda x: int(x.timestamp()*1000)).tolist()\n",
    "    \n",
    "    # Extend date (X-axis) to historical date\n",
    "    X_date_extended1 = pd.date_range(start_date -(days_range) * loops_count,start_date,freq='d').map(lambda x: int(x.timestamp()*1000))\n",
    "    \n",
    "    # Remove first record of extended X\n",
    "    X_date_extended = np.hstack([X_date_extended1, X_date])[1:]\n",
    "    \n",
    "    extended_Y = []\n",
    "    cur_Y = Y\n",
    "    \n",
    "    # Augment Y until X reach historical date\n",
    "    for i in range(0, loops_count):\n",
    "        cur_Y, X = add_noise(cur_Y, X)\n",
    "        extended_Y.append(cur_Y)\n",
    "        \n",
    "    # Append augmented Y to original Y\n",
    "    Y_extended = np.hstack([Y] + extended_Y)\n",
    "    \n",
    "    # Build new DF, ,ap back X from timestime to datetime format\n",
    "    new_df = pd.DataFrame({'datetime': list(map(lambda x: datetime.fromtimestamp(x/1000.0).strftime('%Y-%m-%d'),X_date_extended))})\n",
    "    \n",
    "    # Add Y column and sort the new dataframe by datetime\n",
    "    new_df[metric_type] = pd.Series(Y_extended)\n",
    "    new_df = new_df.sort_values('datetime')\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "36bc811f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zero-size array to reduction operation maximum which has no identity\n",
      "3922265808357194945\n",
      "zero-size array to reduction operation maximum which has no identity\n",
      "2265529010543344118\n",
      "zero-size array to reduction operation maximum which has no identity\n",
      "4036654423970744204\n",
      "zero-size array to reduction operation maximum which has no identity\n",
      "6835791843203149124\n",
      "zero-size array to reduction operation maximum which has no identity\n",
      "5218666880235370347\n",
      "zero-size array to reduction operation maximum which has no identity\n",
      "5353556143556258917\n"
     ]
    }
   ],
   "source": [
    "historical_date = datetime.strptime(HISTORICAL_DATE, '%Y-%m-%d')\n",
    "instanceIds = df_cpu['instanceId'].unique().tolist()\n",
    "df_final = None\n",
    "for instanceId in instanceIds:\n",
    "    try:\n",
    "        df_cpu_i = augment_metrics(df_cpu, instanceId, historical_date, 'cpuUtilization', DATE_FIELDS_CONFIG['metrics'])\n",
    "        df_network_i = augment_metrics(df_network_in, instanceId, historical_date, 'networkIn', DATE_FIELDS_CONFIG['metrics'])\n",
    "        df_network_out_i = augment_metrics(df_network_out, instanceId, historical_date, 'networkOut', DATE_FIELDS_CONFIG['metrics'])\n",
    "        df_vcpus_i = augment_metrics(df_cost_instances_info, instanceId, historical_date, 'vCPUs', 'vCPUs')\n",
    "        df_memory_i = augment_metrics(df_cost_instances_info, instanceId, historical_date, 'memory_gb', 'memory_gb')\n",
    "        df_bandwidth_i = augment_metrics(df_cost_instances_info, instanceId, historical_date, 'bandwidth_gbps', 'bandwidth_gbps')\n",
    "        df_cost_i = augment_metrics(df_cost_instances_info, instanceId, historical_date, 'costInUsd', 'costInUsd')\n",
    "        \n",
    "        df_new = pd.merge(df_cpu_i, df_network_i, on=['datetime'], how='outer')\n",
    "        df_new = pd.merge(df_new, df_network_out_i, on=['datetime'], how='outer')\n",
    "        df_new = pd.merge(df_new, df_vcpus_i, on=['datetime'], how='outer')\n",
    "        df_new = pd.merge(df_new, df_memory_i, on=['datetime'], how='outer')\n",
    "        df_new = pd.merge(df_new, df_bandwidth_i, on=['datetime'], how='outer')\n",
    "        df_new = pd.merge(df_new, df_cost_i, on=['datetime'], how='outer')\n",
    "        df_new['instanceId'] = instanceId\n",
    "        if df_final is not None:\n",
    "            df_final = pd.concat([df_final, df_new])\n",
    "        else:\n",
    "            df_final = df_new\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(instanceId)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "10000ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = df_final.drop(df_final[df_final.datetime < HISTORICAL_DATE].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1ba320a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>cpuUtilization</th>\n",
       "      <th>networkIn</th>\n",
       "      <th>networkOut</th>\n",
       "      <th>vCPUs</th>\n",
       "      <th>memory_gb</th>\n",
       "      <th>bandwidth_gbps</th>\n",
       "      <th>costInUsd</th>\n",
       "      <th>instanceId</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2022-02-20</td>\n",
       "      <td>0.008582</td>\n",
       "      <td>17451.044863</td>\n",
       "      <td>67.058404</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.773680</td>\n",
       "      <td>2084983531904533635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2022-02-21</td>\n",
       "      <td>0.009292</td>\n",
       "      <td>-6202.601734</td>\n",
       "      <td>69.420038</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.839641</td>\n",
       "      <td>2084983531904533635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2022-02-22</td>\n",
       "      <td>0.008949</td>\n",
       "      <td>21430.947361</td>\n",
       "      <td>67.890760</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.940766</td>\n",
       "      <td>2084983531904533635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2022-02-23</td>\n",
       "      <td>0.008145</td>\n",
       "      <td>4833.443798</td>\n",
       "      <td>107.485340</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.588254</td>\n",
       "      <td>2084983531904533635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2022-02-24</td>\n",
       "      <td>0.008616</td>\n",
       "      <td>-10456.035972</td>\n",
       "      <td>74.375590</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.770617</td>\n",
       "      <td>2084983531904533635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>2022-07-30</td>\n",
       "      <td>0.015261</td>\n",
       "      <td>-52830.844564</td>\n",
       "      <td>92.267675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.231569</td>\n",
       "      <td>5681595381851713673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>0.025634</td>\n",
       "      <td>-9269.332498</td>\n",
       "      <td>100.647637</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.502435</td>\n",
       "      <td>5681595381851713673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>2022-08-01</td>\n",
       "      <td>0.018768</td>\n",
       "      <td>-147036.122436</td>\n",
       "      <td>12.548980</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.663850</td>\n",
       "      <td>5681595381851713673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>2022-08-02</td>\n",
       "      <td>0.009884</td>\n",
       "      <td>27404.555652</td>\n",
       "      <td>108.825503</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.182839</td>\n",
       "      <td>5681595381851713673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>2022-08-03</td>\n",
       "      <td>0.007871</td>\n",
       "      <td>-32644.648712</td>\n",
       "      <td>63.477650</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.534260</td>\n",
       "      <td>5681595381851713673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8510 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       datetime  cpuUtilization      networkIn  networkOut  vCPUs  memory_gb  \\\n",
       "60   2022-02-20        0.008582   17451.044863   67.058404    1.0        1.7   \n",
       "61   2022-02-21        0.009292   -6202.601734   69.420038    1.0        1.7   \n",
       "62   2022-02-22        0.008949   21430.947361   67.890760    1.0        1.7   \n",
       "63   2022-02-23        0.008145    4833.443798  107.485340    1.0        1.7   \n",
       "64   2022-02-24        0.008616  -10456.035972   74.375590    1.0        1.7   \n",
       "..          ...             ...            ...         ...    ...        ...   \n",
       "285  2022-07-30        0.015261  -52830.844564   92.267675    1.0        1.7   \n",
       "286  2022-07-31        0.025634   -9269.332498  100.647637    1.0        1.7   \n",
       "287  2022-08-01        0.018768 -147036.122436   12.548980    1.0        1.7   \n",
       "288  2022-08-02        0.009884   27404.555652  108.825503    1.0        1.7   \n",
       "289  2022-08-03        0.007871  -32644.648712   63.477650    1.0        1.7   \n",
       "\n",
       "     bandwidth_gbps  costInUsd           instanceId  \n",
       "60              1.0   0.773680  2084983531904533635  \n",
       "61              1.0   0.839641  2084983531904533635  \n",
       "62              1.0   0.940766  2084983531904533635  \n",
       "63              1.0   0.588254  2084983531904533635  \n",
       "64              1.0   0.770617  2084983531904533635  \n",
       "..              ...        ...                  ...  \n",
       "285             1.0   0.231569  5681595381851713673  \n",
       "286             1.0   0.502435  5681595381851713673  \n",
       "287             1.0   0.663850  5681595381851713673  \n",
       "288             1.0   1.182839  5681595381851713673  \n",
       "289             1.0   0.534260  5681595381851713673  \n",
       "\n",
       "[8510 rows x 9 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d1db0bbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.to_csv('./data/gcp_metrics_augmented.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ee04f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
